# Course schedule
- 
    day1: Intros, objectives, etc.
    day1-intro: >
        Course logistics. Introduction to edge ML.
        Introduction to ML frameworks. 
    day2: Labs
    day2-intro:
        Board setup, deploy a large language model on the Pi. First embedded project!
-
    day1: Introduction to CNN and tranformer models
    day1-intro: >
        Introduction to CNN and transformer models and their mathematical implementation and general architecture.
    day2: Labs
    day2-intro: >
        Classify images, locate people and objects.
-
    day1: ML model training and fine-tuning techniques
    day1-intro: >
         ML model training, fine-tuning with transfer learning, multi-task learning.
    day2: Labs
    day2-intro: >
        Recognize speech, fine tune an LLM.
-
    day1: ML model quantization
    day1-intro: >
        Introduction to various data formats for ML. ML model quantization motivation, techniques. Quantization-aware training.
    day2: Labs
    day2-intro: >
        Using tools (like Galileo) to examine a common public dataset.
-
    day1: PEFT techniques and knowledge distillation
    day1-intro: >
        Parameter-Efficient Fine-Tuning (PEFT) techniques including LoRA, adapter layers. 
        Knowledge distillation overview and techniques. 
    day2: Labs
    day2-intro: >
        Weâ€™ll demonstrate how to convert a pre-trained computer vision model to eight bits. 
-
    day1: Hardware for DNN
    day1-intro: >
        Discussion on accelerator design and its impact on model design and performance.
    day2: Labs
    day2-intro: >
        Train ImageNet model on a Colab notebook.
-
    day1: MLOps
    day1-intro: >
        ML Ops pipeline for automating and simplifying ML workflows. ML Observability. 
    day2: Labs
    day2-intro: >
        Project debugging.

-   day1: Guest lecture
    day2: Labs
    day2-intro: >
        Final project presentation.

-   day1: Memorial day (holiday, no class)
    day2: Project
    day2-intro: >
        Final project presentation.
